import json
import glob
import sqlite3
from datetime import datetime
import os
import logging
import sys
import re
from typing import Optional, Dict, List, Any, Tuple

# Configuração de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('processor.log', mode='w'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DatabaseManager:
    """Classe para gerenciar todas as operações do banco de dados"""
    def __init__(self, db_name: str = 'vulnerabilities.db'):
        self.db_name = db_name
        self.conn = None
        self.table_prefixes = set()  # Armazena apenas os prefixos das tabelas

    def __enter__(self):
        self.conn = sqlite3.connect(self.db_name)
        self.conn.execute("PRAGMA foreign_keys = ON")
        self.create_scan_history_table() # Chama a criação da tabela de histórico no __enter__
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.conn:
            if exc_type is None:
                self.conn.commit()
            else:
                self.conn.rollback()
            self.conn.close()

    def _format_date(self, date_str: str, ip: str) -> str:
        """Formata a data e IP para YYMMDD_IP"""
        try:
            dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            date_part = dt.strftime("%y%m%d")  # Formato: YYMMDD
            ip_part = ip.replace('.', '_')      # Formato: 192_168_1_1
            return f"{date_part}_{ip_part}"
        except:
            # Fallback seguro
            clean_date = date_str[:10].replace('-', '')
            clean_ip = ip.replace('.', '_')
            return f"{clean_date}_{clean_ip}"

    def create_scan_tables(self, scan_date: str, ip: str) -> Dict[str, str]:
        """Cria tabelas para uma data e IP específicos e retorna os nomes"""
        table_prefix = self._format_date(scan_date, ip)
        self.table_prefixes.add(table_prefix)  # Armazena apenas o prefixo
        
        table_names = {
            'hosts': f"scan_{table_prefix}_hosts",
            'ports': f"scan_{table_prefix}_ports",
            'vulns': f"scan_{table_prefix}_vulns",
            'recom': f"scan_{table_prefix}_recom"
        }

        try:
            cursor = self.conn.cursor()
            
            # Cria tabela de hosts
            cursor.execute(f'''
                CREATE TABLE IF NOT EXISTS {table_names['hosts']} (
                    ip TEXT PRIMARY KEY, 
                    scan_date TEXT NOT NULL, 
                    network TEXT DEFAULT '',
                    risk_score REAL DEFAULT 0.0,
                    last_updated TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Cria tabela de portas
            cursor.execute(f'''
                CREATE TABLE IF NOT EXISTS {table_names['ports']} (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    host_ip TEXT NOT NULL, 
                    port INTEGER NOT NULL, 
                    protocol TEXT NOT NULL, 
                    service TEXT DEFAULT '', 
                    version TEXT DEFAULT '',
                    FOREIGN KEY(host_ip) REFERENCES {table_names['hosts']}(ip) ON DELETE CASCADE,
                    UNIQUE(host_ip, port, protocol)
                )
            ''')
            
            # Cria tabela de vulnerabilidades
            cursor.execute(f'''
                CREATE TABLE IF NOT EXISTS {table_names['vulns']} (
                    id TEXT PRIMARY KEY,
                    host_ip TEXT NOT NULL,
                    cvss REAL NOT NULL,
                    description TEXT DEFAULT '',
                    FOREIGN KEY(host_ip) REFERENCES {table_names['hosts']}(ip) ON DELETE CASCADE
                )
            ''')
            
            # Cria tabela de recomendações
            cursor.execute(f'''
                CREATE TABLE IF NOT EXISTS {table_names['recom']} (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    host_ip TEXT NOT NULL,
                    recommendation TEXT NOT NULL,
                    FOREIGN KEY(host_ip) REFERENCES {table_names['hosts']}(ip) ON DELETE CASCADE
                )
            ''')
            
            # Cria índices
            cursor.execute(f'''
                CREATE INDEX IF NOT EXISTS idx_{table_prefix}_vuln_host 
                ON {table_names['vulns']}(host_ip)
            ''')
            cursor.execute(f'''
                CREATE INDEX IF NOT EXISTS idx_{table_prefix}_ports_host 
                ON {table_names['ports']}(host_ip)
            ''')
            
            # Log reduzido apenas para o primeiro IP
            if len(self.table_prefixes) == 1:
                logger.info(f"Modelo de tabelas criado. Prefixo: scan_[DATA_IP]_[tipo]")
            
            return table_names
            
        except sqlite3.Error as e:
            logger.error(f"Erro ao criar tabelas: {str(e)}")
            raise

    # --- INÍCIO DAS NOVAS FUNÇÕES PARA O HISTÓRICO DE SCANS ---
    def create_scan_history_table(self):
        """Cria a tabela para registrar os históricos de scans."""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scan_history (
                prefix_id TEXT PRIMARY KEY,
                scan_date TEXT NOT NULL,
                network TEXT,
                ip_alvo TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        logger.info("Tabela 'scan_history' verificada/criada.")

    def record_scan_history(self, prefix_id: str, scan_date: str, network: str, ip_alvo: str):
        """Registra um scan na tabela de histórico."""
        cursor = self.conn.cursor()
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO scan_history (prefix_id, scan_date, network, ip_alvo)
                VALUES (?, ?, ?, ?)
            ''', (prefix_id, scan_date, network, ip_alvo))
            logger.info(f"Scan '{prefix_id}' registrado no histórico.")
        except sqlite3.Error as e:
            logger.error(f"Erro ao registrar scan no histórico: {str(e)}")
    # --- FIM DAS NOVAS FUNÇÕES ---


def get_latest_reports_dir() -> Optional[str]:
    """Encontra o diretório mais recente de relatórios"""
    dirs = glob.glob('relatorios_scan_*')
    if not dirs:
        logger.error("Nenhum diretório de relatórios encontrado")
        return None
    
    latest_dir = max(dirs, key=os.path.getmtime)
    logger.info(f"Usando diretório mais recente: {latest_dir}")
    return latest_dir

def parse_report_file(file_path: str) -> Optional[Dict[str, Any]]:
    """Processa um arquivo de relatório individual"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
            required_fields = {'ip', 'date', 'network'}
            if not required_fields.issubset(data.keys()):
                missing = required_fields - set(data.keys())
                logger.warning(f"Arquivo {file_path} inválido. Campos faltando: {missing}")
                return None
                
            if 'cves' in data:
                valid_cves = []
                for i, cve in enumerate(data['cves']):
                    if not isinstance(cve, dict):
                        continue
                        
                    cve_id = cve.get('id', '')
                    if not cve_id or cve_id == '|':
                        match = re.search(r'(CVE-\d{4}-\d+)', cve.get('description', ''))
                        if match:
                            cve_id = match.group(1)
                        else:
                            cve_id = f"{data['ip']}_vuln_{i}"
                    
                    try:
                        cvss = float(cve.get('cvss', 0))
                    except (TypeError, ValueError):
                        cvss = 0.0
                    
                    valid_cves.append({
                        'id': cve_id,
                        'cvss': cvss,
                        'description': cve.get('description', '')
                    })
                
                data['cves'] = valid_cves
                
            logger.debug(f"Processando relatório para IP: {data['ip']}")
            return data
            
    except json.JSONDecodeError as e:
        logger.error(f"JSON inválido em {file_path}: {str(e)}")
    except UnicodeDecodeError as e:
        logger.error(f"Problema de codificação em {file_path}: {str(e)}")
    except Exception as e:
        logger.error(f"Erro inesperado ao processar {file_path}: {str(e)}")
    
    return None

def calculate_risk_score(cves: List[Dict[str, Any]]) -> float:
    """Calcula o score de risco baseado no CVSS mais alto encontrado"""
    if not cves:
        return 0.0
    
    try:
        max_cvss = max(float(cve.get('cvss', 0)) for cve in cves)
        return min(max_cvss * 1.2, 10.0)
    except (TypeError, ValueError) as e:
        logger.warning(f"Erro ao calcular risk_score: {str(e)}")
        return 0.0

def import_report_to_tables(db_manager: DatabaseManager, data: Dict[str, Any], table_names: Dict[str, str]) -> bool:
    """Importa um relatório para as tabelas especificadas"""
    ip = data['ip']
    scan_date = data['date']
    network = data.get('network', '')
    
    try:
        cursor = db_manager.conn.cursor()
        
        # Calcula risk_score
        risk_score = calculate_risk_score(data.get('cves', []))
        
        # Insere host
        cursor.execute(f'''
            INSERT OR REPLACE INTO {table_names['hosts']} 
            (ip, scan_date, network, risk_score) 
            VALUES (?, ?, ?, ?)
        ''', (ip, scan_date, network, risk_score))
        
        # Insere portas
        for port in data.get('open_ports', []):
            cursor.execute(f'''
                INSERT OR IGNORE INTO {table_names['ports']} 
                (host_ip, port, protocol, service, version) 
                VALUES (?, ?, ?, ?, ?)
            ''', (
                ip,
                port.get('port'),
                port.get('protocol', 'tcp'),
                port.get('service', ''),
                port.get('version', '')
            ))
        
        # Insere vulnerabilidades
        for cve in data.get('cves', []):
            cve_id = cve.get('id')
            if not cve_id:
                continue
                
            cursor.execute(f'''
                INSERT OR REPLACE INTO {table_names['vulns']} 
                (id, host_ip, cvss, description) 
                VALUES (?, ?, ?, ?)
            ''', (
                cve_id,
                ip,
                cve.get('cvss', 0.0),
                cve.get('description', '')
            ))
        
        # Insere recomendações padrão
        recommendations = [
            "Atualizar todos os serviços listados",
            "Fechar portas não utilizadas",
            "Implementar regras de firewall específicas"
        ]
        
        for rec in recommendations:
            cursor.execute(f'''
                INSERT OR IGNORE INTO {table_names['recom']} 
                (host_ip, recommendation) 
                VALUES (?, ?)
            ''', (ip, rec))
        
        return True
            
    except sqlite3.Error as e:
        logger.error(f"Erro SQL ao importar dados: {str(e)}")
    except Exception as e:
        logger.error(f"Erro inesperado ao importar dados: {str(e)}")
    
    return False

def process_reports(db_manager: DatabaseManager, directory: str) -> Tuple[bool, List[str]]:
    """Processa todos os relatórios em um diretório"""
    if not os.path.isdir(directory):
        logger.error(f"Diretório não encontrado: {directory}")
        return False, []
    
    reports = glob.glob(os.path.join(directory, 'scan_*_*.json'))
    if not reports:
        logger.warning("Nenhum relatório encontrado")
        return False, []
    
    imported = 0
    for report in reports:
        data = parse_report_file(report)
        if not data:
            continue
            
        table_prefix = db_manager._format_date(data['date'], data['ip']) # Garante que o prefixo seja gerado corretamente
        table_names = db_manager.create_scan_tables(data['date'], data['ip'])
        
        if import_report_to_tables(db_manager, data, table_names):
            imported += 1
            # NOVO: Registra o scan no histórico
            db_manager.record_scan_history(table_prefix, data['date'], data.get('network', ''), data['ip'])
    
    success = imported > 0
    created_prefixes = sorted(db_manager.table_prefixes)
    
    logger.info(f"Processamento concluído. Scans realizados: {len(created_prefixes)}")
    return success, created_prefixes

def main():
    try:
        logger.info("Iniciando processamento de relatórios")
        
        with DatabaseManager() as db_manager:
            if len(sys.argv) > 1:
                directory = sys.argv[1]
            else:
                directory = get_latest_reports_dir()
                if not directory:
                    return 1
                
            success, created_prefixes = process_reports(db_manager, directory)
            
            # Saída simplificada
            print("\nRadicais das tabelas criadas (scan_[DATA_IP]_*):")
            for prefix in created_prefixes:
                print(f"- {prefix}")
            
            print("\nExemplo de consulta:")
            if created_prefixes:
                example = created_prefixes[0]
                print(f"SELECT * FROM scan_{example}_hosts;")
                print(f"SELECT * FROM scan_{example}_vulns ORDER BY cvss DESC;")
                
            print("\nPara usar no Metabase, a tabela 'scan_history' agora contém todos os prefixos de scan.")
            print("Crie um filtro de dashboard vinculado à 'scan_history.prefix_id' para dashboards dinâmicos.")
            
            return 0 if success else 1
            
    except Exception as e:
        logger.critical(f"Erro fatal: {str(e)}", exc_info=True)
        return 1

if __name__ == "__main__":
    sys.exit(main())